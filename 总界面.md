# 总界面

主界面包含了在本课程内，此前学到的各种应用的介绍，和进入该应用功能界面的按钮。
![alt 图片](https://github.com/Mingtx1718/Picture/blob/main/m.bmp?raw=true "主界面")

以风格迁移为例，界面包含了图片选择、模型读取、转化功能的按钮。

![alt 图片](https://github.com/Mingtx1718/Picture/blob/main/s.bmp?raw=true "风格迁移界面")

鉴于部分同学们此前完成各项任务时，并不是以函数或类的方法实现的，为了完成主界面和各子界面功能的实现，我们为同学们提供了函数库。

```python
import cv2
import requests
import json
import base64
import numpy as np
from tkinter import *
from tkinter import ttk
from tkinter.filedialog import (askopenfilename, asksaveasfilename)
from PIL import Image, ImageTk
import os
import threading
import pyaudio
import wave
import speech_recognition as sr
from win32com.client import Dispatch
import pyttsx3

# opencv图像转base64
def image2base64(image_np, format):
    image = cv2.imencode(format, image_np)[1]
    image_code = str(base64.b64encode(image))[2:-1]
    return image_code


# base64转opencv图像
def base642image(base64_code):
    img_data = base64.b64decode(base64_code)
    img_array = np.frombuffer(img_data, np.uint8)
    img = cv2.imdecode(img_array, cv2.COLOR_RGB2BGR)
    return img


# 向face++进行请求
def link2facepp(img1, format1, img2, format2):
    img64_1 = image2base64(img1, format1)
    img64_2 = image2base64(img2, format2)
    url = 'https://api-cn.faceplusplus.com/imagepp/v1/mergeface'
    data = {
        "api_key": "i9ac-ZZMEOWqIlRIiLD3oiR26OpAWM43",
        "api_secret": "wad4LNBj41EiWxreH204QlN6WRaOLUZy",
        "template_base64": img64_1,
        "merge_base64": img64_2,
        "merge_rate": 50
    }
    response1 = requests.post(url, data=data)
    return response1


# 解码face++返回的图像为opencv的格式
def ReadFromResponse(response):
    res_con = response.content.decode('utf-8')
    res_dict = json.JSONDecoder().decode(res_con)
    result = res_dict['result']
    img = base642image(result)
    return img


# 构建手写数字识别的knn
def Tr(knn):
    img = cv2.imread('d.png', cv2.IMREAD_GRAYSCALE)
    cells = [np.hsplit(row, 100) for row in np.vsplit(img, 50)]
    x = np.array(cells)
    train = x[:, :].reshape(-1, 400).astype(np.float32)
    k = np.arange(10)
    train_labels = np.repeat(k, 500)[:, np.newaxis]
    knn.train(train, cv2.ml.ROW_SAMPLE, train_labels)
    return knn


# 使用knn进行手写数字识别
def rec(knn, gray):
    gray = cv2.resize(gray, (20, 20))
    test = gray[:, :].reshape(-1, 400).astype(np.float32)
    ret, result, neighbours, dist = knn.findNearest(test, k=5)
    result = np.array(result)
    return result[0, 0].astype(np.uint8)


# 模型集合
model = ['candy.t7', 'composition_vii.t7', 'feathers.t7', 'la_muse.t7', 'mosaic.t7', 'starry_night.t7', 'the_scream.t7', 'the_wave.t7', 'udnie.t7']


def Style_Transfer(net, img):
    img = cv2.resize(img, (400, 400))
    img = cv2.GaussianBlur(img, (7, 7), 0, 0)
    Mean = (np.mean(img[0]), np.mean(img[1]), np.mean(img[2]))
    (h, w) = img.shape[:2]
    blob = cv2.dnn.blobFromImage(img, 0.1, (w, h), Mean, swapRB=False, crop=False)
    net.setInput(blob)
    out = net.forward()
    out = out.reshape(3, out.shape[2], out.shape[3])
    out[0] += Mean[0]
    out[1] += Mean[1]
    out[2] += Mean[2]
    out = out.transpose(1, 2, 0)
    cv2.imwrite('temp.png', out)
    out = cv2.imread('temp.png')
    os.remove('temp.png')
    out = cv2.resize(out, (400, 400))
    mix = 0.5
    M = cv2.medianBlur(img, 5)
    out = cv2.addWeighted(out, mix, M, 1 - mix, 0)
    return out


class Recorder:
    def __init__(self, chunk=1024, channels=1, rate=16000):
        self.CHUNK = chunk
        self.FORMAT = pyaudio.paInt16
        self.CHANNELS = channels
        self.RATE = rate
        self._running = True
        self._frames = []
        self.file = "test.wav"

    def start(self):
        threading._start_new_thread(self._recording, ())

    def _recording(self):
        self._running = True
        print('start recording')
        self._frames = []
        p = pyaudio.PyAudio()
        stream = p.open(format=self.FORMAT,
                        channels=self.CHANNELS,
                        rate=self.RATE,
                        input=True,
                        frames_per_buffer=self.CHUNK)
        while self._running:
            data = stream.read(self.CHUNK)
            self._frames.append(data)

        stream.stop_stream()
        stream.close()
        p.terminate()

    def save(self):
        p = pyaudio.PyAudio()

        wf = wave.open(self.savePath(), 'wb')
        wf.setnchannels(self.CHANNELS)
        wf.setsampwidth(p.get_sample_size(self.FORMAT))
        wf.setframerate(self.RATE)
        wf.writeframes(b''.join(self._frames))
        wf.close()

    def savePath(self):
        path_ = asksaveasfilename(title='保存一个.wav文件', initialdir='/',
                                  filetypes=[('Wave File', '*.wav')])  # 使用askdirectory()方法返回文件夹的路径
        if path_ == "":
            self.savePath(self)  # 当打开文件路径选择框后点击"取消" 输入框会清空路径，所以使用get()方法再获取一次路径
        else:
            path_ = path_.replace("/", "\\")  # 实际在代码中执行的路径为“\“ 所以替换一下
            return path_

    def stop(self):
        self._running = False
        print('stop')

    def play_audio(self, filename=""):
        CHUNK = 1024
        if filename == "":
            filename = self.file
        wf = wave.open(filename, 'rb')
        data = wf.readframes(CHUNK)
        p = pyaudio.PyAudio()

        FORMAT = p.get_format_from_width(wf.getsampwidth())
        CHANNELS = wf.getnchannels()
        RATE = wf.getframerate()

        # print('FORMAT: {} CHANNELS: {} RATE: {}'.format(FORMAT, CHANNELS, RATE))

        stream = p.open(format=FORMAT,
                        channels=CHANNELS,
                        rate=RATE,
                        frames_per_buffer=CHUNK,
                        output=True)

        while len(data) > 0:
            stream.write(data)
            data = wf.readframes(CHUNK)

    @staticmethod
    def rec_audio(file):
        """
        :param: The Absolute Path of the audio file
        :return: Content identified
        """
        r = sr.Recognizer()
        with sr.AudioFile(file) as source:
            audio = r.record(source)
        try:
            # print(r.recognize_sphinx(audio, language='zh-CN'))
            # print(r.recognize_google(audio, language='zh-CN'))
            return r.recognize_google(audio, language='zh-CN')
        except Exception as e:
            print(e)
```

将文件命名为`lib.py`。

在此基础上，同学们可以直接调用函数来完成界面功能的实现，将精力集中到界面布局等方向上去。

以主界面和换脸子界面为例，进行课程讲解，其他子界面则要求同学们自行完成。

```python
from lib import *


class Window:
    def __init__(self):
        self.win = Tk()

    def SetWindow(self):
        print('')

    def OpenWindow(self):
        self.win.mainloop()
```

首先定义一个窗口类，实现最基础的初始化、创建和打开窗口的功能。

```python
class Window1(Window):
    '''
    换脸窗口
    '''
    # 初始化函数
    def __init__(self, par):
        super().__init__()
        self.par = par
        self.img1 = np.zeros((400, 400, 3), np.uint8)
        self.img1.fill(255)
        self.img2 = np.zeros((400, 400, 3), np.uint8)
        self.img2.fill(255)
        self.imgf1 = None
        self.imgf2 = None
        self.p1 = None
        self.p2 = None
        # print('这是初始化函数')

    # 将Label p 的内容设置为 图片img 的内容
    def setpannle(self, img, p):
        current_image = Image.fromarray(img)
        imgtk = ImageTk.PhotoImage(image=current_image)
        p.imgtk = imgtk
        p.config(image=imgtk)

    # 从文件选择图片1
    def Getimg1(self):
        path = askopenfilename(title='窗口标题', filetypes=[('PNG', '*.png'), ('JPG', '*.jpg')])
        path.replace("/", "\\")
        self.img1 = cv2.imread(path)
        self.img1 = cv2.resize(self.img1, (400, 400))
        self.img1 = cv2.cvtColor(self.img1, cv2.COLOR_BGR2RGB)
        self.imgf1 = path[len(path) - 4:len(path)]
        self.setpannle(self.img1, self.p1)
        # print('从文件选择图片1')

    def Getimg2(self):
        path = askopenfilename(title='窗口标题', filetypes=[('PNG', '*.png'), ('JPG', '*.jpg')])
        path.replace("/", "\\")
        self.img2 = cv2.imread(path)
        self.img2 = cv2.resize(self.img2, (400, 400))
        self.img2 = cv2.cvtColor(self.img2, cv2.COLOR_BGR2RGB)
        self.imgf2 = path[len(path) - 4:len(path)]
        self.setpannle(self.img2, self.p2)
        # print('从文件选择图片2')

    def FaceMerge(self):
        response = link2facepp(self.img1, self.imgf1, self.img2, self.imgf2)
        self.img1 = ReadFromResponse(response)
        self.setpannle(self.img1, self.p1)
        # print('换脸')

    def Main(self):
        self.win.destroy()
        self.par.__init__()
        self.par.SetWindow()
        self.par.OpenWindow()

    def SetWindow(self):
        self.win.title("换脸")
        self.win.geometry("800x500")
        f1 = Frame(self.win)
        f2 = Frame(self.win)
        f3 = Frame(self.win)
        f1.pack(side=TOP)
        f2.pack(side=TOP)
        f3.pack(side=BOTTOM)
        Button(f1, text='原图', command=self.Getimg1).pack(side=LEFT)
        Button(f1, text='脸图', command=self.Getimg2).pack(side=LEFT)
        Button(f1, text='换脸', command=self.FaceMerge).pack(side=LEFT)
        self.p1 = Label(f2)
        self.p1.pack(side=LEFT)
        self.p2 = Label(f2)
        self.p2.pack(side=LEFT)
        self.setpannle(self.img1, self.p1)
        self.setpannle(self.img2, self.p2)
        # Button(f3, text='主菜单', command=self.Main).pack(side=TOP)
        self.win.protocol('WM_DELETE_WINDOW', self.Main)
        # print('设置窗口内容')
```

在换脸窗口类内，需要继承窗口类，并设置类内的两个图片变量、两个后缀名变量、两个Lable变量，和父窗口类的对象变量。

我们对之前提供的文件读取进行一些简单的修改，将读取到的图片展示在Lable内，具体的函数也由我们提供。

换脸按钮，将调用lib中的换脸函数，将类内的图片变量1转化为经过换脸后的图片。

我们同样将这张图片展示在窗口内的lable上。

为了使得窗口尺寸固定，我们要对图片进行初始化。

为了使得子窗口退出后能回到主界面，我们要设置窗口的关闭事件。

```python
class Window_C(Window):
    def __init__(self):
        super().__init__()
        self.win.title("主窗口")
        self.win.geometry("300x150")

    def NR(self):
        self.win.destroy()
        w = Window3(self)
        w.SetWindow()
        w.OpenWindow()
        print('手写数字识别')

    def ST(self):
        self.win.destroy()
        w = Window2(self)
        w.SetWindow()
        w.OpenWindow()
        print('风格迁移')

    def FM(self):
        self.win.destroy()
        w = Window1(self)
        w.SetWindow()
        w.OpenWindow()
        print('换脸')

    def YY(self):
        self.win.destroy()
        w = Windowa(self)
        w.SetWindow()
        w.OpenWindow()

    def ID(self):
        self.win.destroy()
        w = Windowi(self)
        w.SetWindow()
        w.OpenWindow()

    def SetWindow(self):
        tab = ttk.Notebook()
        tab.pack(side=LEFT)
        f1 = Frame(tab)
        f2 = Frame(tab)
        f3 = Frame(tab)
        f1.pack(side=LEFT)
        f2.pack(side=LEFT)
        f3.pack(side=LEFT)
        tab.add(f1, text='语音与文字')
        tab.add(f2, text='图像处理')
        tab.add(f3, text='简单应用')


        text1 = Text(f1, width=30, height=5, undo=True, autoseparators=False)
        text1.pack(side=TOP)
        text1.insert(INSERT, '语音与文字模块，包含了文字与语音的相互转换，并提供了录音和保存功能。')
        ttk.Button(f1, text='  语音', command=self.YY).pack(side=TOP)
        text2 = Text(f2, width=30, height=5, undo=True, autoseparators=False)
        text2.pack(side=TOP)
        text2.insert(INSERT, '图像处理功能，包括了彩色图向灰度图、二值图的转化功能。')
        ttk.Button(f2, text='  图像处理', command=self.ID).pack(side=TOP)
        text3 = Text(f3, width=30, height=5, undo=True, autoseparators=False)
        text3.pack(side=TOP)
        text3.insert(INSERT, '简单的人工智能应用，提供了换脸、手写数字识别、风格迁移的功能。')
        ttk.Button(f3, text='手写数字识别', command=self.NR).pack(side=LEFT)
        ttk.Button(f3, text='风格迁移', command=self.ST).pack(side=LEFT)
        ttk.Button(f3, text='换脸', command=self.FM).pack(side=LEFT)

        text1.config(state=DISABLED)
        text2.config(state=DISABLED)
        text3.config(state=DISABLED)

        self.win.attributes('-alpha',0.9)
```

上述功能需要至少三课时完成讲解和学生实践。
